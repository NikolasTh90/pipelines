version: '3.8'

services:
  pipelines:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        - MINIMUM_BUILD=false
        - USE_CUDA=true
        - USE_CUDA_VER=cu124  # Using CUDA 12.4 as a standard version
    ports:
      - "9099:9099"
    volumes:
      - ./:/app  # Mount the current directory to /app in the containerA
      - pipelines_data:/app/pipelines
      # Mount local pipeline directory for development (optional, uncomment if needed)
      # - ./pipelines:/app/pipelines
    environment:
      - HOST=0.0.0.0
      - PORT=9099
      - USE_CUDA=true
      - DEVICE=cuda
      # Pre-install Guardrails components
      - GUARDRAILS_AUTO_INSTALL=true
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - GUARDRAILS_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJnaXRodWJ8NDE3MDY1MzUiLCJhcGlLZXlJZCI6ImQyOTk5ZDIxLTFjYmMtNGQ2YS04MmQwLTZkNmY1NjU3YzNmOCIsInNjb3BlIjoicmVhZDpwYWNrYWdlcyIsInBlcm1pc3Npb25zIjpbXSwiaWF0IjoxNzQzMTUyODU1LCJleHAiOjQ4OTY3NTI4NTV9.LUbwpX0Z6xVol8wCJO6YxUfAX77QUOAE3_-UX70CBRQ
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    extra_hosts:
      - "host.docker.internal:host-gateway"
    command: tail -f /dev/null

volumes:
  pipelines_data:
    # This volume persists pipeline data between container restarts